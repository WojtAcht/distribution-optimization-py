{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from experiments.datasets import DATASETS\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "DATASET_NAMES = [\"truck_driving_data\", \"atmosphere_data\"]\n",
    "\n",
    "DATASET_NAME_TO_DISPLAY_NAME = {\n",
    "    \"truck_driving_data\": \"Truck driving\",\n",
    "    \"atmosphere_data\": \"Atmosphere\",\n",
    "}\n",
    "\n",
    "first_dataset = [dataset for dataset in DATASETS if dataset.name == DATASET_NAMES[0]][0]\n",
    "second_dataset = [dataset for dataset in DATASETS if dataset.name == DATASET_NAMES[1]][\n",
    "    0\n",
    "]\n",
    "\n",
    "first_dataset_scaled_data = scaler.fit_transform(\n",
    "    first_dataset.data.reshape(-1, 1)\n",
    ").reshape(-1)\n",
    "second_dataset_scaled_data = scaler.fit_transform(\n",
    "    second_dataset.data.reshape(-1, 1)\n",
    ").reshape(-1)\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"values\": np.concatenate(\n",
    "            [first_dataset_scaled_data, second_dataset_scaled_data]\n",
    "        ),\n",
    "        \"Dataset\": [DATASET_NAME_TO_DISPLAY_NAME.get(first_dataset.name)]\n",
    "        * len(first_dataset.data)\n",
    "        + [DATASET_NAME_TO_DISPLAY_NAME.get(second_dataset.name)]\n",
    "        * len(second_dataset.data),\n",
    "    }\n",
    ")\n",
    "\n",
    "fig = px.histogram(\n",
    "    data,\n",
    "    x=\"values\",\n",
    "    color=\"Dataset\",\n",
    "    barmode=\"overlay\",\n",
    "    nbins=100,\n",
    "    histnorm=\"probability\",\n",
    "    width=1000,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pflacco.classical_ela_features import *\n",
    "from pflacco.sampling import create_initial_sample\n",
    "from umap import UMAP\n",
    "from distribution_optimization_py.problem import (\n",
    "    ScaledGaussianMixtureProblemForELA,\n",
    "    LinearlyScaledGaussianMixtureProblem,\n",
    ")\n",
    "import random\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "SAMPLE_COEFFICIENT = 250\n",
    "\n",
    "\n",
    "def get_ela_features(problem):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    dim = len(problem.lower)\n",
    "    X = create_initial_sample(\n",
    "        dim,\n",
    "        lower_bound=-5,\n",
    "        upper_bound=5,\n",
    "        sample_coefficient=SAMPLE_COEFFICIENT,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    y = X.apply(lambda x: problem(x), axis=1)\n",
    "    ela_meta = calculate_ela_meta(X, y)\n",
    "    ela_distr = calculate_ela_distribution(X, y)\n",
    "    ela_pca = calculate_pca(X, y)\n",
    "    ela_level = calculate_ela_level(X, y)\n",
    "    nbc = calculate_nbc(X, y)\n",
    "    disp = calculate_dispersion(X, y)\n",
    "    ic = calculate_information_content(X, y, seed=SEED)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            **ic,\n",
    "            **ela_meta,\n",
    "            **ela_distr,\n",
    "            **nbc,\n",
    "            **disp,\n",
    "            **ela_pca,\n",
    "            **ela_level,\n",
    "            **{\"dim\": dim},\n",
    "            **{\"seed\": SEED},\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_gaussian_ela_features(calculate_linearly_scaled: bool = False) -> None:\n",
    "    ela_features_dfs = []\n",
    "\n",
    "    for dataset in DATASETS:\n",
    "        scaled_problem = ScaledGaussianMixtureProblemForELA(\n",
    "            dataset.data, dataset.nr_of_modes\n",
    "        )\n",
    "        ela_features_df = get_ela_features(scaled_problem)\n",
    "        ela_features_df[\"fid\"] = f\"{dataset.name} *\"\n",
    "        ela_features_df[\"iid\"] = 1\n",
    "        ela_features_dfs.append(ela_features_df)\n",
    "        if calculate_linearly_scaled:\n",
    "            problem = LinearlyScaledGaussianMixtureProblem(\n",
    "                dataset.data, dataset.nr_of_modes, lower=-5, upper=5\n",
    "            )\n",
    "            ela_features_df = get_ela_features(problem)\n",
    "            ela_features_df[\"fid\"] = dataset.name\n",
    "            ela_features_df[\"iid\"] = 1\n",
    "            ela_features_dfs.append(ela_features_df)\n",
    "    return pd.concat(ela_features_dfs)\n",
    "\n",
    "\n",
    "if os.listdir().count(\"gaussian_ela_features.csv\") == 0:\n",
    "    gaussian_features_df = calculate_gaussian_ela_features()\n",
    "    gaussian_features_df.to_csv(\"gaussian_ela_features.csv\", index=False)\n",
    "else:\n",
    "    gaussian_features_df = pd.read_csv(\"gaussian_ela_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.listdir().count(\"ela_features_improved.csv\") != 0, \"Please run `save_ela_features.py` first.\"\n",
    "\n",
    "bbob_features_df = pd.read_csv(\"ela_features_improved.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_CLASSES = (\n",
    "    [\"separable\"] * 5\n",
    "    + [\"low-conditioning\"] * 4\n",
    "    + [\"unimodal\"] * 5\n",
    "    + [\"multimodal-adequate\"] * 5\n",
    "    + [\"multimodal-weak\"] * 5\n",
    ")\n",
    "\n",
    "\n",
    "def get_problem_class(fid: str | int) -> str:\n",
    "    if isinstance(fid, int):\n",
    "        return PROBLEM_CLASSES[fid - 1]\n",
    "    return \"distribution-optimization\"\n",
    "\n",
    "\n",
    "all_features_df = pd.concat([bbob_features_df, gaussian_features_df])\n",
    "all_features_df[\"class\"] = [get_problem_class(fid) for fid in all_features_df[\"fid\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"disp.ratio_mean_02\",\n",
    "    \"ela_distr.skewness\",\n",
    "    \"ela_meta.lin_simple.adj_r2\",\n",
    "    \"ela_meta.lin_simple.intercept\",\n",
    "    \"ela_meta.lin_simple.coef.max\",\n",
    "    \"ela_meta.quad_simple.adj_r2\",\n",
    "    \"ic.eps_ratio\",\n",
    "    \"ic.eps_s\",\n",
    "    \"nbc.nb_fitness.cor\",\n",
    "    \"pca.expl_var_PC1.cov_init\",\n",
    "]\n",
    "\n",
    "METADATA_COLUMNS = [\"dim\", \"iid\", \"fid\", \"seed\", \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "dim_8_index = all_features_df[\"dim\"] == 8\n",
    "dim_14_index = all_features_df[\"dim\"] == 14\n",
    "\n",
    "dim_8_features = all_features_df[dim_8_index].drop(columns=METADATA_COLUMNS)\n",
    "dim_14_features = all_features_df[dim_14_index].drop(columns=METADATA_COLUMNS)\n",
    "dim_8_metadata = all_features_df[dim_8_index][METADATA_COLUMNS]\n",
    "dim_14_metadata = all_features_df[dim_14_index][METADATA_COLUMNS]\n",
    "\n",
    "scaled_dim_8_features = pd.DataFrame(\n",
    "    scaler.fit_transform(dim_8_features), columns=dim_8_features.columns\n",
    ")\n",
    "scaled_dim_14_features = pd.DataFrame(\n",
    "    scaler.fit_transform(dim_14_features), columns=dim_14_features.columns\n",
    ")\n",
    "\n",
    "scaled_dim_8_features = pd.concat(\n",
    "    [dim_8_metadata.reset_index(drop=True), scaled_dim_8_features], axis=1\n",
    ")\n",
    "scaled_dim_14_features = pd.concat(\n",
    "    [dim_14_metadata.reset_index(drop=True), scaled_dim_14_features], axis=1\n",
    ")\n",
    "\n",
    "scaled_all_features = pd.concat([scaled_dim_8_features, scaled_dim_14_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "bbob_without_metadata_features_df = bbob_features_df.drop(\n",
    "    columns=METADATA_COLUMNS, errors=\"ignore\"\n",
    ")\n",
    "scaler.fit(bbob_without_metadata_features_df)\n",
    "scaled_all_features_df = pd.DataFrame(\n",
    "    scaler.transform(all_features_df[bbob_without_metadata_features_df.columns]),\n",
    "    columns=bbob_without_metadata_features_df.columns,\n",
    ")\n",
    "umap = UMAP(n_components=2, random_state=42)\n",
    "umap_all = umap.fit_transform(scaled_all_features_df[FEATURES])\n",
    "umap_df = pd.DataFrame(umap_all, columns=[\"UMAP-1\", \"UMAP-2\"])\n",
    "umap_df[\"class\"] = all_features_df[\"class\"].values\n",
    "color_map = {\n",
    "    \"distribution-optimization\": \"red\",\n",
    "    \"low-conditioning\": \"green\",\n",
    "    \"separable\": \"pink\",\n",
    "    \"unimodal\": \"orange\",\n",
    "    \"multimodal-adequate\": \"blue\",\n",
    "    \"multimodal-weak\": \"purple\",\n",
    "}\n",
    "\n",
    "fig = px.scatter(\n",
    "    umap_df,\n",
    "    x=\"UMAP-1\",\n",
    "    y=\"UMAP-2\",\n",
    "    color=\"class\",\n",
    "    # title=\"UMAP Projection of ELA Features with Problem Class Labels\",\n",
    "    width=1200,  # width in pixels\n",
    "    height=1200,  # height in pixels\n",
    "    color_discrete_map=color_map,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to check if the model is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = bbob_features_df[FEATURES]\n",
    "y = [get_problem_class(fid) for fid in bbob_features_df[\"fid\"]]\n",
    "\n",
    "assert len(X) == len(y)\n",
    "assert \"class\" not in X.columns\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    RandomForestClassifier(random_state=42),\n",
    ")\n",
    "\n",
    "cross_val_score(pipeline, X, y, cv=10, scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting problem class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_all_features\n",
    "train_index = scaled_all_features[\"class\"] != \"distribution-optimization\"\n",
    "test_index = scaled_all_features[\"class\"] == \"distribution-optimization\"\n",
    "\n",
    "X_train = scaled_all_features[train_index][FEATURES]\n",
    "y_train = scaled_all_features[train_index][\"class\"]\n",
    "X_test = scaled_all_features[test_index][FEATURES]\n",
    "\n",
    "assert len(X_train) == len(y_train)\n",
    "assert \"class\" not in X_train.columns\n",
    "assert \"class\" not in X_test.columns\n",
    "\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting fid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_all_features\n",
    "train_index = scaled_all_features[\"class\"] != \"distribution-optimization\"\n",
    "test_index = scaled_all_features[\"class\"] == \"distribution-optimization\"\n",
    "\n",
    "X_train = scaled_all_features[train_index][FEATURES]\n",
    "y_train = scaled_all_features[train_index][\"fid\"].values.astype(int)\n",
    "X_test = scaled_all_features[test_index][FEATURES]\n",
    "\n",
    "assert len(X_train) == len(y_train)\n",
    "assert \"class\" not in X_train.columns\n",
    "assert \"class\" not in X_test.columns\n",
    "\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
